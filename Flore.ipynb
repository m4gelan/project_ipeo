{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import shutil\n",
    "\n",
    "from tifffile import tifffile \n",
    "#tifffile is a usefull and lightweight library to read raster images (.tif)\n",
    "# example how to use tiffile here : https://pypi.org/project/tifffile/#examples\n",
    "# install it with :\n",
    "# ! pip install tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General information about the data: {'description': 'Large Rocks Detection Dataset ', 'version': '1.0', 'year': 2024, 'contributor': 'Valerie Zermatten', 'date_created': '2024/09/30'}\n",
      "Number of samples  : 992\n",
      "Looking at the the first images: 2581_1126_2_2.tif\n",
      "Looking at rocks annotations for the first images:\n",
      " {'rock_id': 1459.0, 'abs_rock_coordinates': [2581767.93, 1126509.48], 'pixel_within_patch_coordinates': [608.0, 51.0], 'relative_within_patch_location': [0.95, 0.08]}\n"
     ]
    }
   ],
   "source": [
    "# Illustration of some samples coming from the dataset\n",
    "json_file_path = 'Data/large_rock_dataset.json'\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "print('General information about the data:', data['info'])\n",
    "dataset =data['dataset']\n",
    "print('Number of samples  :', len(dataset) )\n",
    "sample_info = dataset[10]\n",
    "print('Looking at the the first images:', sample_info ['file_name'])\n",
    "print('Looking at rocks annotations for the first images:\\n', sample_info ['rocks_annotations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'split': {'test', 'train'}\n"
     ]
    }
   ],
   "source": [
    "unique_splits = set(sample['split'] for sample in dataset)\n",
    "print(\"Unique values in 'split':\", unique_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "base_dir = 'dataset_surface_hillshade'\n",
    "train_images_folder = os.path.join(base_dir, 'train_images')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_images_folder, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "## DONE:\n",
    "\n",
    "# # Iterate through all samples\n",
    "# for sample in dataset:\n",
    "#     file_name = 'Data/swissSURFACE3D_hillshade_patches/' + sample['file_name']\n",
    "#     split = sample['split']  # Assuming the \"split\" key indicates train/test/val\n",
    "\n",
    "#     # Define source and destination paths\n",
    "#     src_path = file_name  # Assuming file_name contains the full or relative path\n",
    "#     if split == 'train':\n",
    "#         dest_dir = train_dir\n",
    "#     elif split == 'test':\n",
    "#         dest_dir = test_dir\n",
    "#     # elif split == 'val':\n",
    "#     #     dest_dir = val_dir\n",
    "#     else:\n",
    "#         print(f\"Unknown split '{split}' for file '{file_name}'. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     dest_path = os.path.join(dest_dir, os.path.basename(file_name))\n",
    "\n",
    "#     # Copy file to the appropriate directory\n",
    "#     try:\n",
    "#         shutil.copy(src_path, dest_path)\n",
    "#         print(f\"Copied '{file_name}' to '{dest_dir}'\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error copying '{file_name}': {e}\")\n",
    "\n",
    "# print(\"Dataset split completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels\n",
    "\n",
    "# Define paths\n",
    "train_labels_folder = os.path.join(base_dir, 'train_labels')\n",
    "\n",
    "# Create the train_labels directory if it doesn't exist\n",
    "os.makedirs(train_labels_folder, exist_ok=True)\n",
    "\n",
    "# DONE:\n",
    "\n",
    "# Process images with split == 'train'\n",
    "# for sample in dataset:\n",
    "#     if sample['split'] == 'train':\n",
    "#         # Extract relevant details\n",
    "#         file_name = sample['file_name']\n",
    "#         annotations = sample.get('rocks_annotations', [])\n",
    "        \n",
    "#         # Create a .txt file for this image\n",
    "#         base_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "#         txt_file_path = os.path.join(labels_dir, f\"{base_name}.txt\")\n",
    "        \n",
    "#         # Write annotations to the .txt file\n",
    "#         with open(txt_file_path, 'w') as txt_file:\n",
    "#             for annotation in annotations:\n",
    "#                 txt_file.write(f\"{annotation}\\n\")\n",
    "        \n",
    "#         print(f\"Created annotation file: {txt_file_path}\")\n",
    "\n",
    "# print(\"All train annotations have been saved to the 'train_labels' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in train set: 576\n"
     ]
    }
   ],
   "source": [
    "# Create Validation Set\n",
    "file_count = len([file for file in os.listdir(train_images_folder) if os.path.isfile(os.path.join(train_images_folder, file))])\n",
    "print(f\"Number of images in train set: {file_count}\")\n",
    "\n",
    "# Define source and destination folders\n",
    "source_folder = train_images_folder\n",
    "destination_folder = os.path.join(base_dir, 'val_images')\n",
    "\n",
    "# DONE:\n",
    "\n",
    "# List all files in the source folder\n",
    "# files = [file for file in os.listdir(source_folder) if os.path.isfile(os.path.join(source_folder, file))]\n",
    "\n",
    "# # Calculate 10% of the total files\n",
    "# num_files_to_move = max(1, int(len(files) * 0.1))  # Ensure at least one file is moved\n",
    "\n",
    "# # Randomly select 10% of the files\n",
    "# files_to_move = random.sample(files, num_files_to_move)\n",
    "\n",
    "# # Move the selected files\n",
    "# for file in files_to_move:\n",
    "#     src_path = os.path.join(source_folder, file)\n",
    "#     dest_path = os.path.join(destination_folder, file)\n",
    "#     shutil.move(src_path, dest_path)\n",
    "#     print(f\"Moved '{file}' to '{destination_folder}'\")\n",
    "\n",
    "# print(f\"Moved {len(files_to_move)} files to '{destination_folder}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths\n",
    "val_images_folder = os.path.join(base_dir, 'val_images')\n",
    "val_labels_folder = os.path.join(base_dir, 'val_labels')\n",
    "\n",
    "# DONE:\n",
    "\n",
    "# Create the val_labels folder if it doesn't exist\n",
    "# os.makedirs(val_labels_folder, exist_ok=True)\n",
    "\n",
    "# # List all image files in val_images folder (excluding extensions)\n",
    "# val_image_files = {os.path.splitext(file)[0] for file in os.listdir(val_images_folder) if os.path.isfile(os.path.join(val_images_folder, file))}\n",
    "\n",
    "# # Move matching label files from train_labels to val_labels\n",
    "# for label_file in os.listdir(train_labels_folder):\n",
    "#     # Get the base name (without extension) of the label file\n",
    "#     base_name = os.path.splitext(label_file)[0]\n",
    "    \n",
    "#     if base_name in val_image_files:\n",
    "#         src_path = os.path.join(train_labels_folder, label_file)\n",
    "#         dest_path = os.path.join(val_labels_folder, label_file)\n",
    "#         shutil.move(src_path, dest_path)\n",
    "#         print(f\"Moved '{label_file}' to '{val_labels_folder}'\")\n",
    "\n",
    "# print(\"Matching label files moved to 'val_labels' folder.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Read the image and labels\u001b[39;00m\n\u001b[0;32m     41\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m---> 42\u001b[0m img_height, img_width \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(label_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m label_file:\n\u001b[0;32m     45\u001b[0m     labels \u001b[38;5;241m=\u001b[39m label_file\u001b[38;5;241m.\u001b[39mreadlines()  \u001b[38;5;66;03m# Assuming each line is \"class x y\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Data augmentation\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Paths for images and labels\n",
    "aug_images_folder = 'aug_train_images'\n",
    "aug_labels_folder = 'aug_train_labels'\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "os.makedirs(aug_images_folder, exist_ok=True)\n",
    "os.makedirs(aug_labels_folder, exist_ok=True)\n",
    "\n",
    "def flip_image_and_labels(image, labels, img_width, flip_type):\n",
    "    \"\"\"Flip image and update labels.\"\"\"\n",
    "    if flip_type == 'horizontal':\n",
    "        flipped_image = cv2.flip(image, 1)  # Flip horizontally\n",
    "        flipped_labels = [\n",
    "            f\"{label.split()[0]} {img_width - float(label.split()[1])} {label.split()[2]}\"\n",
    "            for label in labels\n",
    "        ]\n",
    "    elif flip_type == 'vertical':\n",
    "        flipped_image = cv2.flip(image, 0)  # Flip vertically\n",
    "        flipped_labels = [\n",
    "            f\"{label.split()[0]} {label.split()[1]} {1 - float(label.split()[2])}\"\n",
    "            for label in labels\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown flip_type. Use 'horizontal' or 'vertical'.\")\n",
    "    return flipped_image, flipped_labels\n",
    "\n",
    "# Process each image and label\n",
    "for file in os.listdir(train_images_folder):\n",
    "    if file.endswith('.tif'):\n",
    "        image_path = os.path.join(train_images_folder, file)\n",
    "        label_path = os.path.join(train_labels_folder, file.replace('.tif', '.txt'))\n",
    "        \n",
    "        # Read the image and labels\n",
    "        image = cv2.imread(image_path)\n",
    "        img_height, img_width = image.shape[:2]\n",
    "        \n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readlines()  # Assuming each line is \"class x y\"\n",
    "        \n",
    "        # Augmentations: Horizontal Flip\n",
    "        flipped_image, flipped_labels = flip_image_and_labels(image, labels, img_width, 'horizontal')\n",
    "        flipped_image_path = os.path.join(aug_images_folder, f\"{file.replace('.tif', '_flipped.tif')}\")\n",
    "        flipped_label_path = os.path.join(aug_labels_folder, f\"{file.replace('.tif', '_flipped.txt')}\")\n",
    "\n",
    "        # Save the flipped image and labels\n",
    "        cv2.imwrite(flipped_image_path, flipped_image)\n",
    "        with open(flipped_label_path, 'w') as flipped_label_file:\n",
    "            flipped_label_file.write(\"\\n\".join(flipped_labels))\n",
    "        print(f\"Saved augmented image and label: {flipped_image_path}, {flipped_label_path}\")\n",
    "\n",
    "print(\"Data augmentation completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipeo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
