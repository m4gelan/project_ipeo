{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import re\n",
    "\n",
    "from tifffile import tifffile \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete - Illustration of some samples coming from the dataset\n",
    "json_file_path = 'Data/large_rock_dataset.json'\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "print('General information about the data:', data['info'])\n",
    "dataset =data['dataset']\n",
    "print('Number of samples  :', len(dataset) )\n",
    "sample_info = dataset[10]\n",
    "print('Looking at the the first images:', sample_info ['file_name'])\n",
    "print('Looking at rocks annotations for the first images:\\n', sample_info ['rocks_annotations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete - vis\n",
    "unique_splits = set(sample['split'] for sample in dataset)\n",
    "print(\"Unique values in 'split':\", unique_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete - Dataset organisation for hillshade \n",
    "\n",
    "# TRAIN/TEST\n",
    "base_dir = 'dataset_surface_hillshade'\n",
    "# base_dir = 'dataset_swissimage'\n",
    "train_images_folder = os.path.join(base_dir, 'train_images')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "# os.makedirs(base_dir, exist_ok=True)\n",
    "# os.makedirs(train_images_folder, exist_ok=True)\n",
    "# os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "## DONE:\n",
    "\n",
    "# Iterate through all samples\n",
    "# for sample in dataset:\n",
    "#     file_name = 'Data/swissImage_50cm_patches/' + sample['file_name']\n",
    "#     split = sample['split']  # Assuming the \"split\" key indicates train/test/val\n",
    "\n",
    "#     # Define source and destination paths\n",
    "#     src_path = file_name  # Assuming file_name contains the full or relative path\n",
    "#     if split == 'train':\n",
    "#         dest_dir = train_images_folder\n",
    "#     elif split == 'test':\n",
    "#         dest_dir = test_dir\n",
    "#     # elif split == 'val':\n",
    "#     #     dest_dir = val_dir\n",
    "#     else:\n",
    "#         print(f\"Unknown split '{split}' for file '{file_name}'. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     dest_path = os.path.join(dest_dir, os.path.basename(file_name))\n",
    "\n",
    "#     # Copy file to the appropriate directory\n",
    "#     try:\n",
    "#         shutil.copy(src_path, dest_path)\n",
    "#         print(f\"Copied '{file_name}' to '{dest_dir}'\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error copying '{file_name}': {e}\")\n",
    "\n",
    "# print(\"Dataset split completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete - Dataset organisation for hillshade \n",
    "\n",
    "# train_labels\n",
    "train_labels_folder = os.path.join(base_dir, 'train_labels')\n",
    "\n",
    "# Create the train_labels directory if it doesn't exist\n",
    "# os.makedirs(train_labels_folder, exist_ok=True)\n",
    "\n",
    "# DONE:\n",
    "\n",
    "# Process images with split == 'train'\n",
    "# for sample in dataset:\n",
    "#     if sample['split'] == 'train':\n",
    "#         # Extract relevant details\n",
    "#         file_name = sample['file_name']\n",
    "#         annotations = sample.get('rocks_annotations', [])\n",
    "        \n",
    "#         # Create a .txt file for this image\n",
    "#         base_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "#         txt_file_path = os.path.join(train_labels_folder, f\"{base_name}.txt\")\n",
    "        \n",
    "#         # Write annotations to the .txt file\n",
    "#         with open(txt_file_path, 'w') as txt_file:\n",
    "#             for annotation in annotations:\n",
    "#                 txt_file.write(f\"{annotation}\\n\")\n",
    "        \n",
    "#         print(f\"Created annotation file: {txt_file_path}\")\n",
    "\n",
    "# print(\"All train annotations have been saved to the 'train_labels' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete - Dataset organisation for hillshade \n",
    "\n",
    "# Create Validation Set - images\n",
    "file_count = len([file for file in os.listdir(train_images_folder) if os.path.isfile(os.path.join(train_images_folder, file))])\n",
    "print(f\"Number of images in train set: {file_count}\")\n",
    "\n",
    "# Define folder\n",
    "val_images_folder = os.path.join(base_dir, 'val_images')\n",
    "# os.makedirs(val_images_folder, exist_ok=True)\n",
    "\n",
    "# DONE:\n",
    "\n",
    "# List all files in the source folder\n",
    "# files = [file for file in os.listdir(train_images_folder) if os.path.isfile(os.path.join(train_images_folder, file))]\n",
    "\n",
    "# # Calculate 10% of the total files\n",
    "# num_files_to_move = max(1, int(len(files) * 0.1))  # Ensure at least one file is moved\n",
    "\n",
    "# # Randomly select 10% of the files\n",
    "# files_to_move = random.sample(files, num_files_to_move)\n",
    "\n",
    "# # Move the selected files\n",
    "# for file in files_to_move:\n",
    "#     src_path = os.path.join(train_images_folder, file)\n",
    "#     dest_path = os.path.join(val_images_folder, file)\n",
    "#     shutil.move(src_path, dest_path)\n",
    "#     print(f\"Moved '{file}' to '{val_images_folder}'\")\n",
    "\n",
    "# print(f\"Moved {len(files_to_move)} files to '{val_images_folder}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete - Dataset organisation for hillshade \n",
    "\n",
    "# Create Validation Set - labels\n",
    "val_labels_folder = os.path.join(base_dir, 'val_labels')\n",
    "# os.makedirs(val_labels_folder, exist_ok=True)\n",
    "\n",
    "# DONE:\n",
    "\n",
    "# List all image files in val_images folder (excluding extensions)\n",
    "# val_image_files = {os.path.splitext(file)[0] for file in os.listdir(val_images_folder) if os.path.isfile(os.path.join(val_images_folder, file))}\n",
    "\n",
    "# # Move matching label files from train_labels to val_labels\n",
    "# for label_file in os.listdir(train_labels_folder):\n",
    "#     # Get the base name (without extension) of the label file\n",
    "#     base_name = os.path.splitext(label_file)[0]\n",
    "    \n",
    "#     if base_name in val_image_files:\n",
    "#         src_path = os.path.join(train_labels_folder, label_file)\n",
    "#         dest_path = os.path.join(val_labels_folder, label_file)\n",
    "#         shutil.move(src_path, dest_path)\n",
    "#         print(f\"Moved '{label_file}' to '{val_labels_folder}'\")\n",
    "\n",
    "# print(\"Matching label files moved to 'val_labels' folder.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete (?) - DONE:\n",
    "\n",
    "# Path to the folder containing .tif images\n",
    "# folder_path = 'dataset_swissimage/val_images'\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "# for file in os.listdir(folder_path):\n",
    "#     if file.endswith('.tif'):\n",
    "#         # Full path to the .tif file\n",
    "#         tif_path = os.path.join(folder_path, file)\n",
    "        \n",
    "#         # Open the .tif file\n",
    "#         try:\n",
    "#             with Image.open(tif_path) as img:\n",
    "#                 # Define the output path with the same name but .jpg extension\n",
    "#                 jpg_path = os.path.join(folder_path, file.replace('.tif', '.jpg'))\n",
    "                \n",
    "#                 # Convert and save as JPG\n",
    "#                 img.convert('RGB').save(jpg_path, 'JPEG')\n",
    "                \n",
    "#                 # Remove the original .tif file\n",
    "#                 os.remove(tif_path)\n",
    "#                 print(f\"Converted and replaced: {file} -> {jpg_path}\")\n",
    "        \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# print(\"All .tif files have been converted to .jpg and replaced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete (?) - label in form for Yolo8\n",
    "\n",
    "# Input and output directories\n",
    "label_input_folder = val_labels_folder  # Folder containing original label files\n",
    "label_output_folder = os.path.join(base_dir, 'yolo_val_labels')  # Folder for YOLO-compliant labels\n",
    "# os.makedirs(label_output_folder, exist_ok=True)\n",
    "\n",
    "# DONE:\n",
    "\n",
    "# YOLOv8 assumes constant bbox size based on your description\n",
    "# bbox_width = 10 / 640  # Normalized width\n",
    "# bbox_height = 10 / 640  # Normalized height\n",
    "\n",
    "# # Process each label file\n",
    "# for label_file in os.listdir(label_input_folder):\n",
    "#     if label_file.endswith('.txt'):  # Process only text files\n",
    "#         input_path = os.path.join(label_input_folder, label_file)\n",
    "#         output_path = os.path.join(label_output_folder, label_file)\n",
    "\n",
    "#         with open(input_path, 'r') as infile, open(output_path, 'w') as outfile:\n",
    "#             # Read each line in the file and extract dictionaries\n",
    "#             for line in infile:\n",
    "#                 line = line.strip()\n",
    "#                 if not line:\n",
    "#                     continue\n",
    "                \n",
    "#                 # Parse the dictionary using regex\n",
    "#                 match = re.search(r\"'relative_within_patch_location': \\[(\\d+\\.\\d+), (\\d+\\.\\d+)\\]\", line)\n",
    "#                 if match:\n",
    "#                     x_center = float(match.group(1))  # Normalized x_center\n",
    "#                     y_center = float(match.group(2))  # Normalized y_center\n",
    "\n",
    "#                     # Write to YOLO format: class_id, x_center, y_center, width, height\n",
    "#                     class_id = 0  # Assuming 'rock' class is class 0\n",
    "#                     outfile.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\")\n",
    "        \n",
    "#         print(f\"Processed: {label_file}\")\n",
    "\n",
    "# print(\"Conversion to YOLOv8 format completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 640, 640])\n",
      "Labels: tensor([[0.0000, 0.4400, 0.2700, 0.0156, 0.0156],\n",
      "        [0.0000, 0.5100, 0.3900, 0.0156, 0.0156],\n",
      "        [0.0000, 0.5700, 0.4500, 0.0156, 0.0156],\n",
      "        [0.0000, 0.5700, 0.3800, 0.0156, 0.0156],\n",
      "        [0.0000, 0.3700, 0.7600, 0.0156, 0.0156],\n",
      "        [0.0000, 0.3000, 0.7100, 0.0156, 0.0156],\n",
      "        [0.0000, 0.3900, 0.9200, 0.0156, 0.0156]])\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "import dataset as dt   \n",
    "\n",
    "image_folder = \"dataset_swissimage/train_images\"\n",
    "label_folder = \"dataset_swissimage/yolo_train_labels\"\n",
    "\n",
    "mean, std = dt.calculate_mean_std(image_folder)\n",
    "\n",
    "dataset = dt.RockDetectionDataset(\n",
    "    image_folder=image_folder,\n",
    "    label_folder=label_folder,\n",
    "    mean=mean,\n",
    "    std=std\n",
    ")\n",
    "\n",
    "# Access a sample\n",
    "for img, lbl in dataset:\n",
    "    print(\"Image shape:\", img.shape)\n",
    "    print(\"Labels:\", lbl)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images shape: torch.Size([4, 3, 640, 640])\n",
      "Batch labels (per image):\n",
      "  Image 0: torch.Size([0, 5])\n",
      "  Image 1: torch.Size([5, 5])\n",
      "  Image 2: torch.Size([0, 5])\n",
      "  Image 3: torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=dt.custom_collate_fn)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch_images, batch_labels in dataloader:\n",
    "    print(\"Batch images shape:\", batch_images.shape)  # Example: [4, 3, 640, 640]\n",
    "    print(\"Batch labels (per image):\")\n",
    "    for i, labels in enumerate(batch_labels):\n",
    "        print(f\"  Image {i}: {labels.shape}\")  # Example: [N, 5] or [0, 5] for empty labels\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n"
     ]
    }
   ],
   "source": [
    "file_count = len([f for f in os.listdir('dataset_swissimage/train_images') if os.path.isfile(os.path.join('dataset_swissimage/train_images', f))])\n",
    "print(file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 1 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 2 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 3 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 4 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 5 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 6 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 7 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 8 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 9 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 10 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 11 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 12 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 13 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 14 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 15 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 16 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 17 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 18 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 19 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 20 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 21 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 22 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 23 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 24 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 25 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 26 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 27 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 28 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 29 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 30 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 31 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 32 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 33 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 34 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 35 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 36 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 37 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 38 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 39 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 40 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 41 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 42 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 43 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 44 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 45 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 46 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 47 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 48 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 49 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 50 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 51 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 52 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 53 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 54 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 55 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 56 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 57 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 58 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 59 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 60 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 61 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 62 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 63 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 64 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 65 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 66 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 67 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 68 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 69 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 70 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 71 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 72 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 73 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 74 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 75 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 76 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 77 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 78 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 79 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 80 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 81 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 82 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 83 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 84 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 85 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 86 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 87 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 88 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 89 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 90 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 91 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 92 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 93 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 94 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 95 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 96 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 97 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 98 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 99 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 100 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 101 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 102 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 103 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 104 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 105 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 106 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 107 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 108 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 109 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 110 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 111 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 112 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 113 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 114 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 115 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 116 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 117 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 118 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 119 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 120 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 121 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 122 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 123 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 124 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 125 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 126 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 127 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 128 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 129 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 130 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 131 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 132 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 133 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 134 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 135 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 136 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 137 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 138 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 139 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 140 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 141 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 142 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 143 images to dataset_swissimage/normalized_images.\n",
      "Saved batch 144 images to dataset_swissimage/normalized_images.\n"
     ]
    }
   ],
   "source": [
    "# SAVE NORMALISED IMAGES\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Folder to save the normalized images\n",
    "output_folder = \"dataset_swissimage/normalized_images\"\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Iterate through the DataLoader and save normalized images\n",
    "# for batch_idx, (batch_images, batch_labels) in enumerate(dataloader):\n",
    "#     for i, image_tensor in enumerate(batch_images):\n",
    "#         # Denormalize the image for saving\n",
    "#         denormalized_image = image_tensor.clone()  # Create a copy to modify\n",
    "#         denormalized_image[0] = denormalized_image[0] * std[0] + mean[0]  # R\n",
    "#         denormalized_image[1] = denormalized_image[1] * std[1] + mean[1]  # G\n",
    "#         denormalized_image[2] = denormalized_image[2] * std[2] + mean[2]  # B\n",
    "        \n",
    "#         # Save the image\n",
    "#         output_path = os.path.join(output_folder, f\"batch_{batch_idx + 1}_image_{i + 1}.jpg\")\n",
    "#         save_image(denormalized_image, output_path)\n",
    "    \n",
    "#     print(f\"Saved batch {batch_idx + 1} images to {output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA AUG - EXO 7\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "# mean and standard deviation of the dataset\n",
    "mean=torch.tensor([0.504, 0.504, 0.503])\n",
    "std=torch.tensor([0.019 , 0.018, 0.018])\n",
    "\n",
    "# normalize image [0-1] (or 0-255) to zero-mean unit standard deviation\n",
    "normalize = T.Normalize(mean, std)\n",
    "# we invert normalization for plotting later\n",
    "std_inv = 1 / (std + 1e-7)\n",
    "unnormalize = T.Normalize(-mean * std_inv, std_inv)\n",
    "\n",
    "transforms_train = T.Compose([\n",
    "  #TODO: add your own transforms here\n",
    "  T.RandomResizedCrop((200, 200)),\n",
    "  T.RandomGrayscale(),\n",
    "  T.RandomHorizontalFlip(),\n",
    "  T.RandomApply([T.GaussianBlur(kernel_size=7)]),\n",
    "  T.RandomPosterize(bits=8),\n",
    "  T.RandomVerticalFlip(),\n",
    "  T.ColorJitter(),\n",
    "  T.Resize((224, 224)),\n",
    "  T.ToTensor(),\n",
    "  normalize\n",
    "])\n",
    "\n",
    "# we do not augment the validation dataset (aside from resizing and tensor casting)\n",
    "transforms_val = T.Compose([\n",
    "  T.Resize((224, 224)),\n",
    "  T.ToTensor(),\n",
    "  normalize\n",
    "])\n",
    "\n",
    "# Test\n",
    "dataset_index = 500\n",
    "\n",
    "img, label = dataset[dataset_index]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(12,6))\n",
    "axs[0].imshow(unnormalize(transforms_val(img)).permute(1,2,0))\n",
    "axs[0].set_title(\"validation transform (no augmentation)\")\n",
    "\n",
    "axs[1].imshow(unnormalize(transforms_train(img)).permute(1,2,0))\n",
    "axs[1].set_title(\"training transform\")\n",
    "[ax.axis(\"off\") for ax in axs] # removes ticks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipeo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
