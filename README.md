# Comparison of Yolov8 versions on large rocks detection

## Introduction

The Federal Office for Topography (swisstopo) undertakes the precise and labor-intensive task of manually annotating large rocks (over 5x5 meters) across Switzerland for the production of topographic maps. With advancements in automatic detection methods, swisstopo seeks to explore the feasibility of integrating such technologies to enhance efficiency and accuracy in their workflows.

This project investigates the application of the YOLOv8 object detection framework on swisstopo's large rock detection dataset. Specifically, we evaluate the performance of two YOLOv8 versions—'nano' and 'large'—trained on the dataset. The models are first trained on the provided training dataset and subsequently fine-tuned using the validation dataset to optimize their parameters. Finally, we analyze the models' performance on the test dataset by visualizing the results and computing a range of evaluation metrics.

One of the key challenges in this work lies in the complexity and variability of natural data. Factors such as varying lighting conditions, shadows, dense forest canopies, and the presence of man-made structures like houses introduce significant noise and ambiguity in the detection process. These challenges necessitate robust training methodologies and comprehensive evaluation to ensure the models can generalize effectively across diverse environmental conditions.

WHY LARGE OVER NANO ????

This study aims to provide a systematic evaluation of YOLOv8's capabilities for large rock detection, offering insights into the potential integration of modern machine learning techniques into geospatial annotation workflows.

## Large Rocks Dataset

The Large Rocks Dataset serves as the foundation for this project and is derived from high-resolution imagery and terrain models annotated by swisstopo. It offers a unique opportunity to compare traditional geospatial analysis techniques (e.g., local maximum detection, rugosity indices) with recent advancements in object detection models.

**Dataset Characteristics**

- Study Area: The dataset spans regions in Valais, Ticino, and Graubünden, which feature diverse topographical and environmental conditions.

- Geographic Splitting: Tiles are geographically divided into training and testing sets to ensure robust evaluation of model performance.

**Data Composition**
- Aerial Imagery: High-resolution RGB images (50 cm resolution) from swissIMAGE.
Provides detailed visual representation of the landscape.
- Digital Surface Model (DSM): Terrain elevation data at 50 cm resolution derived from LiDAR through swissSURFACE3D. Captures 3D surface details critical for identifying large rock structures.
- Hillshade Raster: Generated from DSM data using QGIS (Azimuth: 0°, Vertical Angle: 0°). Highlights surface topography through shaded relief, aiding in the visual detection of rock features.
- Annotations: Comprehensive point annotations for 2,625 large rocks provided by swisstopo experts. Forms the ground truth for training and evaluation of detection models.

**Dataset Access**
The dataset can be downloaded from the following link:
[Large Rocks Dataset - Download Here](https://enacshare.epfl.ch/bY2wS5TcA4CefGks7NtXg)

## Pipeline Description

The pipeline implemented for the large rock detection project is structured into distinct stages to effectively prepare, preprocess, and organize the dataset for training YOLOv8 models. The approach integrates data fusion, augmentation, and reorganization into YOLO-compatible formats.

### Data Preprocessing

**Combining DSM and RGB Data:**
A novel input format is created by replacing the red band of RGB images with the hillshade greyscale derived from the Digital Surface Model (DSM). This fusion enhances the representation of topographical features critical for rock detection.

**Dataset Splitting:**
The dataset is split into training and testing sets based on metadata provided in the large_rock_dataset.json file. This process is handled by the function split_train_from_json which organizes the data into corresponding directories.
A validation set is generated by randomly selecting 10% of the training images (create_validation_set_images and create_validation_set_labels).
Normalization and Augmentation:

For the training dataset, a PyTorch-compatible dataset is created with normalization parameters calculated using calculate_mean_std.
Data augmentation is applied to enhance the model's robustness:
Geometric Transformations: Horizontal and vertical flips (geometric_augmentations).
Brightness Adjustment: Variations in image brightness and contrast (brightning).
Random Obstruction: Addition of 10x10 pixel black squares to simulate occlusions (obstruction).
Dataset Organization:

All data is reorganized into a YOLO-compatible format, with separate directories for images and labels under train, val, and test folders. Labels are converted to YOLO format using convert_labels_to_yolo_format.
Pipeline Output
The organized dataset is prepared for YOLOv8 training with comprehensive data augmentation and topographically enriched inputs. This pipeline ensures that the model receives high-quality, diverse data for effective learning and evaluation.



















## Code: 'Inference.py'

### Data Preprocessing

combination : We combine the DSM and RGB data by replacing the red band by the hillshade greyscale....
Split into train/test thanks to the 'large_rock_dataset.json' where the apartenance of each image to test or train is given. 
We create a validation set by taking randomly 10% of the thraning images.
Only for train images we put them in a pytorch dataset with normalisation
Using this tensor dataset we compute three augemntations, geometric (horizontal and vertical flip), random brighting and random obstruction of 10x10 pixel black squares.
Finally, we organise everything in a folder in a format for yolo like this:
dataset/
    ├── train/
    │   ├── images/
    │   │   ├── img1.jpg
    │   │   └── img2.jpg
    │   └── labels/
    │       ├── img1.txt
    │       └── img2.txt
    ├── val/
    │   ├── images/
    │   │   ├── img3.jpg
    │   │   └── img4.jpg
    │   └── labels/
    │       ├── img3.txt
    │       └── img4.txt
    └── test/
        ├── images/

### Model training

How we did it. Here is the diferent trained models : ...........

### Results of the different versions

Taking a small sample of the preprocessed images we visualise the results and evaluation metrics.
