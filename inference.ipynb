{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Rocks Detection Project\n",
    "\n",
    "Welcome to the **Large Rocks Detection Project**! This notebook serves to implement our machine learning pipeline for detecting large rocks. Below is an outline of the steps we will follow throughout the project:\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. **Dataset Preparation**  \n",
    "   Organize and adapt the training, validation, and test datasets using `dataset.py`.\n",
    "2. **Data Augmentation**  \n",
    "   Apply geometric and visual transformations for enhanced generalization, leveraging `dataset.py`.\n",
    "3. **Model Training**  \n",
    "   Train the model using `model.py`.\n",
    "4. **Regularization to Combat Overfitting**  \n",
    "   Employ validation strategies to minimize overfitting.\n",
    "5. **Evaluation on Test Data**  \n",
    "   Test the model on the final dataset and visualize the results.\n",
    "6. **Accuracy Metrics**  \n",
    "   Calculate and report accuracy metrics for a comprehensive performance evaluation.\n",
    "\n",
    "Letâ€™s dive into each step and build a robust solution for detecting large rocks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import tifffile \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import shutil\n",
    "import dataset as dt\n",
    "import organisation as  org\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "Download the given data ... (in a folder named 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All .tif files have been converted to .jpg and replaced.\n",
      "All .tif files have been converted to .jpg and replaced.\n",
      "Images have been combined and saved.\n"
     ]
    }
   ],
   "source": [
    "# Combine RGB and hillshade images - the red band is replaced by hillshade\n",
    "\n",
    "# Define the paths for the folders\n",
    "rgb_folder_origin = 'Data/swissImage_50cm_patches/'\n",
    "hillshade_folder_origin = 'Data/swissSURFACE3D_hillshade_patches/'\n",
    "\n",
    "rgb_folder = 'rgb_images/'\n",
    "os.makedirs(rgb_folder, exist_ok=True)\n",
    "shutil.copytree(rgb_folder_origin, rgb_folder, dirs_exist_ok=True)\n",
    "\n",
    "hillshade_folder = 'hillshade_images/'\n",
    "os.makedirs(hillshade_folder, exist_ok=True)\n",
    "shutil.copytree(hillshade_folder_origin, hillshade_folder, dirs_exist_ok=True)\n",
    "\n",
    "dt.convert_tif_to_jpg(rgb_folder)\n",
    "dt.convert_tif_to_jpg(hillshade_folder)\n",
    "\n",
    "combined_img_folder = 'combined_images/'\n",
    "os.makedirs(combined_img_folder, exist_ok=True)\n",
    "\n",
    "# Get the list of image names in the RGB folder\n",
    "image_names = os.listdir(rgb_folder)\n",
    "\n",
    "for image_name in image_names:\n",
    "    # Construct full file paths\n",
    "    rgb_path = os.path.join(rgb_folder, image_name)\n",
    "    hillshade_path = os.path.join(hillshade_folder, image_name)\n",
    "    output_path = os.path.join(combined_img_folder, image_name)\n",
    "\n",
    "    # Load the RGB and hillshade images\n",
    "    rgb_image = cv2.imread(rgb_path)\n",
    "    hillshade_image = cv2.imread(hillshade_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check if both images are loaded correctly\n",
    "    if rgb_image is None or hillshade_image is None:\n",
    "        print(f\"Error loading images for {image_name}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Replace the red channel in the RGB image with the hillshade image\n",
    "    rgb_image[:, :, 2] = hillshade_image  # OpenCV uses BGR format, so red channel is index 2\n",
    "\n",
    "    # Save the modified image to the output folder\n",
    "    cv2.imwrite(output_path, rgb_image)\n",
    "\n",
    "print(\"Images have been combined and saved.\")\n",
    "\n",
    "shutil.rmtree(rgb_folder)\n",
    "shutil.rmtree(hillshade_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed.\n",
      "All train annotations have been saved to the 'train_labels' folder.\n",
      "Moved 64 files to 'dataset_combined_images\\val_images'.\n",
      "Matching label files moved to 'val_labels' folder.\n",
      "Conversion to YOLOv8 format completed.\n",
      "Conversion to YOLOv8 format completed.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from JSON\n",
    "json_file_path = 'Data/large_rock_dataset.json' \n",
    "data, dataset = dt.load_dataset_from_json(json_file_path)\n",
    "\n",
    "# Define base directory name where the images and labels will be stored\n",
    "base_dir_name = f'dataset_combined_images'\n",
    "\n",
    "# Split and organize the dataset\n",
    "train_images, test = dt.split_train_from_json(dataset, combined_img_folder, base_dir_name)\n",
    "train_labels = dt.save_train_annotations(dataset, base_dir_name)\n",
    "\n",
    "# Create a validation set\n",
    "val_images = dt.create_validation_set_images(train_images, base_dir_name)\n",
    "val_labels = dt.create_validation_set_labels(train_labels, base_dir_name)\n",
    "\n",
    "# Write the labels in Yolov8 format\n",
    "# YOLOv8 assumes constant bbox size \n",
    "bbox_width = 30 / 640  # Normalized width\n",
    "bbox_height = 30 / 640  # Normalized height\n",
    "\n",
    "dt.convert_labels_to_yolo_format(\n",
    "    train_labels,\n",
    "    base_dir_name,\n",
    "    bbox_width=bbox_width,\n",
    "    bbox_height=bbox_height,\n",
    "    type='train'\n",
    ")\n",
    "\n",
    "dt.convert_labels_to_yolo_format(\n",
    "    val_labels,\n",
    "    base_dir_name,\n",
    "    bbox_width=bbox_width,\n",
    "    bbox_height=bbox_height,\n",
    "    type='val'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 2581_1126_0_0.jpg\n",
      "Image Shape: torch.Size([3, 640, 640])\n",
      "Labels: tensor([[0.0000, 0.4400, 0.2700, 0.0469, 0.0469],\n",
      "        [0.0000, 0.5100, 0.3900, 0.0469, 0.0469],\n",
      "        [0.0000, 0.5700, 0.4500, 0.0469, 0.0469],\n",
      "        [0.0000, 0.5700, 0.3800, 0.0469, 0.0469],\n",
      "        [0.0000, 0.3700, 0.7600, 0.0469, 0.0469],\n",
      "        [0.0000, 0.3000, 0.7100, 0.0469, 0.0469],\n",
      "        [0.0000, 0.3900, 0.9200, 0.0469, 0.0469]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize and inspect the dataset\n",
    "\n",
    "# Set paths for training images and YOLO-format labels.\n",
    "image_folder = \"dataset_combined_images/train_images\"\n",
    "label_folder = \"dataset_combined_images/yolo_train_labels\"\n",
    "\n",
    "# Calculate mean and standard deviation for normalization.\n",
    "mean, std = dt.calculate_mean_std(image_folder)\n",
    "\n",
    "# Create the RockDetectionDataset with normalization (no augmentation for now).\n",
    "dataset = dt.RockDetectionDataset(image_folder, label_folder, mean, std, augment=False)\n",
    "\n",
    "# Iterate through the dataset to:\n",
    "#  - Print the image name, tensor shape, and associated labels.\n",
    "#  - Break after the first iteration for quick inspection.\n",
    "for idx, (aug_images, aug_labels) in enumerate(dataset):\n",
    "    image_name = dataset.image_files[idx]  # Get the name of the current image\n",
    "    print(f\"Image Name: {image_name}\")\n",
    "    print(f\"Image Shape: {aug_images.size()}\")\n",
    "    print(f\"Labels: {aug_labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geometric augmentation completed.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation Workflow: Geometric, Brightness, and Obstruction\n",
    "# This script performs three types of augmentations (Geometric, Brightness, and Obstruction)\n",
    "# and saves the augmented datasets into separate folders.\n",
    "\n",
    "# Parameters\n",
    "batch_size = 16 \n",
    "\n",
    "# Geometric\n",
    "output_image_folder_g = os.path.join(combined_img_folder, \"augmented_train_images_geom\")\n",
    "output_label_folder_g = os.path.join(combined_img_folder, \"augmented_train_labels_geom\")\n",
    "\n",
    "org.aug_pipeline_geom(dataset, mean, std, batch_size, output_image_folder_g, output_label_folder_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brightning augmentation completed.\n"
     ]
    }
   ],
   "source": [
    "# Brightness\n",
    "output_image_folder_b = os.path.join(combined_img_folder, \"augmented_train_images_brightning\")\n",
    "output_label_folder_b = os.path.join(combined_img_folder, \"augmented_train_labels_brightning\")\n",
    "\n",
    "org.aug_pipeline_brightning(dataset, mean, std, batch_size, output_image_folder_b, output_label_folder_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obstruction augmentation completed.\n"
     ]
    }
   ],
   "source": [
    "# Obstruction\n",
    "output_image_folder_o = os.path.join(combined_img_folder, \"augmented_train_images_obstruction\")\n",
    "output_label_folder_o = os.path.join(combined_img_folder, \"augmented_train_labels_obstruction\")\n",
    "\n",
    "org.aug_pipeline_obstruction(dataset, mean, std, batch_size, output_image_folder_o, output_label_folder_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all datasets in one, organised for Yolov8 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug.organize_yolo_dataset(rgb_folder, hillshade_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipeo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
