{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Rocks Detection Project\n",
    "\n",
    "Welcome to the **Large Rocks Detection Project**! This notebook serves to implement our machine learning pipeline for detecting large rocks. Below is an outline of the steps we will follow throughout the project:\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. **Dataset Preparation**  \n",
    "   Organize and adapt the training, validation, and test datasets using `dataset.py`.\n",
    "2. **Data Augmentation**  \n",
    "   Apply geometric and visual transformations for enhanced generalization, leveraging `dataset.py`.\n",
    "3. **Model Training**  \n",
    "   Train the model using `model.py`.\n",
    "4. **Regularization to Combat Overfitting**  \n",
    "   Employ validation strategies to minimize overfitting.\n",
    "5. **Evaluation on Test Data**  \n",
    "   Test the model on the final dataset and visualize the results.\n",
    "6. **Accuracy Metrics**  \n",
    "   Calculate and report accuracy metrics for a comprehensive performance evaluation.\n",
    "\n",
    "Letâ€™s dive into each step and build a robust solution for detecting large rocks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import tifffile \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import dataset as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "Download the given data ... (in a folder named 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed.\n",
      "All train annotations have been saved to the 'train_labels' folder.\n",
      "Moved 64 files to 'dataset_swissImage_50cm_patches\\val_images'.\n",
      "Matching label files moved to 'val_labels' folder.\n",
      "All .tif files have been converted to .jpg and replaced.\n",
      "All .tif files have been converted to .jpg and replaced.\n",
      "Conversion to YOLOv8 format completed.\n",
      "Conversion to YOLOv8 format completed.\n",
      "Dataset split completed.\n",
      "All train annotations have been saved to the 'train_labels' folder.\n",
      "Moved 64 files to 'dataset_swissSURFACE3D_hillshade_patches\\val_images'.\n",
      "Matching label files moved to 'val_labels' folder.\n",
      "All .tif files have been converted to .jpg and replaced.\n",
      "All .tif files have been converted to .jpg and replaced.\n",
      "Conversion to YOLOv8 format completed.\n",
      "Conversion to YOLOv8 format completed.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from JSON\n",
    "json_file_path = 'Data/large_rock_dataset.json'\n",
    "data, dataset = dt.load_dataset_from_json(json_file_path)\n",
    "\n",
    "# Define which type of images you want to use (here we use RGB and hillshade)\n",
    "img_folders = ['Data/swissImage_50cm_patches/', 'Data/swissSURFACE3D_hillshade_patches/']\n",
    "\n",
    "for i in img_folders:\n",
    "    # Extract folder name from the path\n",
    "    folder_name = os.path.basename(os.path.normpath(i))\n",
    "\n",
    "    # Define base directory name where the images and labels will be stored\n",
    "    base_dir_name = f'dataset_{folder_name}'\n",
    "\n",
    "    # Split and organize the dataset\n",
    "    train_images, test = dt.split_train_from_json(dataset, i, base_dir_name)\n",
    "    train_labels = dt.save_train_annotations(dataset, base_dir_name)\n",
    "\n",
    "    # Create a validation set\n",
    "    val_images = dt.create_validation_set_images(train_images, base_dir_name)\n",
    "    val_labels = dt.create_validation_set_labels(train_labels, base_dir_name)\n",
    "\n",
    "    # Convert. tif to .jpg for Yolov8\n",
    "    dt.convert_tif_to_jpg(train_images)\n",
    "    dt.convert_tif_to_jpg(val_images)\n",
    "\n",
    "    # Write the labels in Yolov8 format\n",
    "    # YOLOv8 assumes constant bbox size\n",
    "    bbox_width = 10 / 640  # Normalized width\n",
    "    bbox_height = 10 / 640  # Normalized height\n",
    "\n",
    "    dt.convert_labels_to_yolo_format(\n",
    "        train_labels,\n",
    "        base_dir_name,\n",
    "        bbox_width=bbox_width,\n",
    "        bbox_height=bbox_height,\n",
    "        type='train'\n",
    "    )\n",
    "    \n",
    "    dt.convert_labels_to_yolo_format(\n",
    "        val_labels,\n",
    "        base_dir_name,\n",
    "        bbox_width=bbox_width,\n",
    "        bbox_height=bbox_height,\n",
    "        type='val'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation\n",
    "\n",
    "### For RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 2581_1126_0_0.jpg\n",
      "Image Shape: torch.Size([3, 640, 640])\n",
      "Labels: tensor([[0.0000, 0.4400, 0.2700, 0.0156, 0.0156],\n",
      "        [0.0000, 0.5100, 0.3900, 0.0156, 0.0156],\n",
      "        [0.0000, 0.5700, 0.4500, 0.0156, 0.0156],\n",
      "        [0.0000, 0.5700, 0.3800, 0.0156, 0.0156],\n",
      "        [0.0000, 0.3700, 0.7600, 0.0156, 0.0156],\n",
      "        [0.0000, 0.3000, 0.7100, 0.0156, 0.0156],\n",
      "        [0.0000, 0.3900, 0.9200, 0.0156, 0.0156]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize and inspect the dataset\n",
    "\n",
    "# Set paths for training images and YOLO-format labels.\n",
    "image_folder = \"dataset_swissImage_50cm_patches/train_images\"\n",
    "label_folder = \"dataset_swissImage_50cm_patches/yolo_train_labels\"\n",
    "\n",
    "# Calculate mean and standard deviation for normalization.\n",
    "mean, std = dt.calculate_mean_std(image_folder)\n",
    "\n",
    "# Create the RockDetectionDataset with normalization (no augmentation for now).\n",
    "dataset = dt.RockDetectionDataset(image_folder, label_folder, mean, std, augment=False)\n",
    "\n",
    "# Iterate through the dataset to:\n",
    "#  - Print the image name, tensor shape, and associated labels.\n",
    "#  - Break after the first iteration for quick inspection.\n",
    "for idx, (aug_images, aug_labels) in enumerate(dataset):\n",
    "    image_name = dataset.image_files[idx]  # Get the name of the current image\n",
    "    print(f\"Image Name: {image_name}\")\n",
    "    print(f\"Image Shape: {aug_images.size()}\")\n",
    "    print(f\"Labels: {aug_labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Workflow: Geometric, Brightness, and Obstruction\n",
    "# This script performs three types of augmentations (Geometric, Brightness, and Obstruction)\n",
    "# and saves the augmented datasets into separate folders.\n",
    "\n",
    "# Parameters\n",
    "batch_size = 16 \n",
    "base_dir = 'dataset_swissImage_50cm_patches'\n",
    "augmentations = [\n",
    "    {\"type\": \"geometric\", \"function\": dt.geometric_augmentations, \"output_suffix\": \"geom\"},\n",
    "    {\"type\": \"brightness\", \"function\": dt.brightning, \"output_suffix\": \"bright\"},\n",
    "    {\"type\": \"obstruction\", \"function\": dt.obstruction, \"output_suffix\": \"obst\"}\n",
    "]\n",
    "\n",
    "for augmentation in augmentations:\n",
    "    # Define output paths for the current augmentation\n",
    "    output_image_folder = os.path.join(base_dir, f\"augmented_train_images_{augmentation['output_suffix']}\")\n",
    "    output_label_folder = os.path.join(base_dir, f\"augmented_train_labels_{augmentation['output_suffix']}\")\n",
    "\n",
    "    # Batch processing loop\n",
    "    batch_images, batch_labels, batch_names = [], [], []\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        # Load original image and labels\n",
    "        original_image, original_labels = dataset[idx]\n",
    "        original_image_name = dataset.image_files[idx]  # Get image name\n",
    "\n",
    "        # Convert tensor to PIL image if needed\n",
    "        if isinstance(original_image, torch.Tensor):\n",
    "            original_image = dt.denormalize(original_image.clone(), mean, std)\n",
    "            original_image = T.ToPILImage()(original_image)\n",
    "\n",
    "        # Perform augmentations using the specified function\n",
    "        augmented_data = augmentation[\"function\"](original_image, original_labels)\n",
    "\n",
    "        # Append each augmented image and labels to the batch\n",
    "        for aug_idx, (aug_image, aug_labels) in enumerate(augmented_data):\n",
    "            batch_images.append([aug_image])  # Wrap in a list for batch saving\n",
    "            batch_labels.append([aug_labels])\n",
    "            batch_names.append(f\"{original_image_name}_aug_{aug_idx + 1}\")\n",
    "\n",
    "        # When batch is full, save the batch\n",
    "        if len(batch_images) >= batch_size:\n",
    "            dt.save_augmented_data_batch(\n",
    "                batch_images, batch_labels, batch_names,\n",
    "                output_image_folder, output_label_folder,\n",
    "                augmentation_names=[f\"aug_{i + 1}\" for i in range(len(batch_images))],\n",
    "                mean=mean, std=std\n",
    "            )\n",
    "            # Reset batch\n",
    "            batch_images, batch_labels, batch_names = [], [], []\n",
    "\n",
    "    # Save remaining images in the last batch\n",
    "    if len(batch_images) > 0:\n",
    "        dt.save_augmented_data_batch(\n",
    "            batch_images, batch_labels, batch_names,\n",
    "            output_image_folder, output_label_folder,\n",
    "            augmentation_names=[f\"aug_{i + 1}\" for i in range(len(batch_images))],\n",
    "            mean=mean, std=std\n",
    "        )\n",
    "\n",
    "print(\"Data augmentation complete for all types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fore hillshade images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and inspect the dataset\n",
    "\n",
    "# Set paths for training images and YOLO-format labels.\n",
    "image_folder = \"dataset_swissSURFACE3D_hillshade_patches/train_images\"\n",
    "label_folder = \"dataset_swissSURFACE3D_hillshade_patches/yolo_train_labels\"\n",
    "\n",
    "# Calculate mean and standard deviation for normalization.\n",
    "mean, std = dt.calculate_mean_std(image_folder)\n",
    "\n",
    "# Create the RockDetectionDataset with normalization (no augmentation for now).\n",
    "dataset = dt.RockDetectionDataset(image_folder, label_folder, mean, std, augment=False)\n",
    "\n",
    "# Iterate through the dataset to:\n",
    "#  - Print the image name, tensor shape, and associated labels.\n",
    "#  - Break after the first iteration for quick inspection.\n",
    "for idx, (aug_images, aug_labels) in enumerate(dataset):\n",
    "    image_name = dataset.image_files[idx]  # Get the name of the current image\n",
    "    print(f\"Image Name: {image_name}\")\n",
    "    print(f\"Image Shape: {aug_images.size()}\")\n",
    "    print(f\"Labels: {aug_labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Workflow: Geometric, Brightness, and Obstruction\n",
    "# This script performs three types of augmentations (Geometric, Brightness, and Obstruction)\n",
    "# and saves the augmented datasets into separate folders.\n",
    "\n",
    "# Parameters\n",
    "batch_size = 16 \n",
    "base_dir = 'dataset_swissSURFACE3D_hillshade_patches'\n",
    "augmentations = [\n",
    "    {\"type\": \"geometric\", \"function\": dt.geometric_augmentations, \"output_suffix\": \"geom\"},\n",
    "    {\"type\": \"brightness\", \"function\": dt.brightning, \"output_suffix\": \"bright\"},\n",
    "    {\"type\": \"obstruction\", \"function\": dt.obstruction, \"output_suffix\": \"obst\"}\n",
    "]\n",
    "\n",
    "for augmentation in augmentations:\n",
    "    # Define output paths for the current augmentation\n",
    "    output_image_folder = os.path.join(base_dir, f\"augmented_train_images_{augmentation['output_suffix']}\")\n",
    "    output_label_folder = os.path.join(base_dir, f\"augmented_train_labels_{augmentation['output_suffix']}\")\n",
    "\n",
    "    # Batch processing loop\n",
    "    batch_images, batch_labels, batch_names = [], [], []\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        # Load original image and labels\n",
    "        original_image, original_labels = dataset[idx]\n",
    "        original_image_name = dataset.image_files[idx]  # Get image name\n",
    "\n",
    "        # Convert tensor to PIL image if needed\n",
    "        if isinstance(original_image, torch.Tensor):\n",
    "            original_image = dt.denormalize(original_image.clone(), mean, std)\n",
    "            original_image = T.ToPILImage()(original_image)\n",
    "\n",
    "        # Perform augmentations using the specified function\n",
    "        augmented_data = augmentation[\"function\"](original_image, original_labels)\n",
    "\n",
    "        # Append each augmented image and labels to the batch\n",
    "        for aug_idx, (aug_image, aug_labels) in enumerate(augmented_data):\n",
    "            batch_images.append([aug_image])  # Wrap in a list for batch saving\n",
    "            batch_labels.append([aug_labels])\n",
    "            batch_names.append(f\"{original_image_name}_aug_{aug_idx + 1}\")\n",
    "\n",
    "        # When batch is full, save the batch\n",
    "        if len(batch_images) >= batch_size:\n",
    "            dt.save_augmented_data_batch(\n",
    "                batch_images, batch_labels, batch_names,\n",
    "                output_image_folder, output_label_folder,\n",
    "                augmentation_names=[f\"aug_{i + 1}\" for i in range(len(batch_images))],\n",
    "                mean=mean, std=std\n",
    "            )\n",
    "            # Reset batch\n",
    "            batch_images, batch_labels, batch_names = [], [], []\n",
    "\n",
    "    # Save remaining images in the last batch\n",
    "    if len(batch_images) > 0:\n",
    "        dt.save_augmented_data_batch(\n",
    "            batch_images, batch_labels, batch_names,\n",
    "            output_image_folder, output_label_folder,\n",
    "            augmentation_names=[f\"aug_{i + 1}\" for i in range(len(batch_images))],\n",
    "            mean=mean, std=std\n",
    "        )\n",
    "\n",
    "print(\"Data augmentation complete for all types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipeo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
